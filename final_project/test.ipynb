{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# suppress silly log messages from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import structure_prediction_utils as utils\n",
    "from Autoencoder import AutoEncoder\n",
    "# import resnet_model as res\n",
    "import res_autoencoder as res\n",
    "import vit_model as vit\n",
    "importlib.reload(res)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# # import time\n",
    "\n",
    "# def save_to_file(avg_loss_list_epochs, avg_mse_loss_list_epochs, validate_loss_list_epochs):\n",
    "#     # 创建新的文件夹以存储损失记录\n",
    "#     timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     folder_name = 'each_epochs_loss'\n",
    "#     os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "#     # 创建文件路径\n",
    "#     file_path = os.path.join(folder_name, f'each_epochs_loss_{timestamp}.csv')\n",
    "\n",
    "#     # 将损失值保存到 CSV 文件中\n",
    "#     with open(file_path, mode='w', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         # 写入表头\n",
    "#         writer.writerow(['Epoch', 'Avg Loss', 'Avg MSE Loss', 'Validation Loss'])\n",
    "        \n",
    "#         # 写入每一轮的损失值\n",
    "#         for i in range(len(avg_loss_list_epochs)):\n",
    "#             writer.writerow([i + 1, avg_loss_list_epochs[i], avg_mse_loss_list_epochs[i], validate_loss_list_epochs[i]])\n",
    "\n",
    "#     print(f\"Loss records saved to '{file_path}'\")\n",
    "\n",
    "# # 示例调用\n",
    "# avg_loss_list_epochs = [0.1, 0.2, 0.3]  # 示例数据\n",
    "# avg_mse_loss_list_epochs = [0.05, 0.1, 0.15]\n",
    "# validate_loss_list_epochs = [0.08, 0.18, 0.25]\n",
    "# save_to_file(avg_loss_list_epochs, avg_mse_loss_list_epochs, validate_loss_list_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([1806.5  322.7 6882.9], shape=(3,), dtype=float32)\n",
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_folder = './'\n",
    "training_records = utils.load_preprocessed_data(data_folder, 'training.tfr')\n",
    "validate_records = utils.load_preprocessed_data(data_folder, 'validation.tfr')\n",
    "test_records = utils.load_preprocessed_data(data_folder, 'testing.tfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor0(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f\"inputs x shape is: {primary_one_hot.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(8, 8))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(8, 8))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=1, key_dim=2)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f\"inputs x shape is: {primary_one_hot.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        attention_output = self.attention(x, x, x)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = x + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = primary_one_hot + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor4(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        # self.encoder = Encoder()\n",
    "        # self.decoder = Decoder()\n",
    "        self.autencode = AutoEncoder()\n",
    "        self.resnet = res.resnet50()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = primary_one_hot + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        x = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = self.encoder(x)\n",
    "        # print(f'after encoder shape is {x.shape}')\n",
    "        # x = self.decoder(x)\n",
    "        # print(f'after decoder shape is {x.shape}')\n",
    "        x = self.autencode(x)\n",
    "        print(f'autencode shape is {x.shape}')\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor5(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(7, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        self.resnet = res.resnet34()\n",
    "        self.add = keras.layers.Add()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(f\"mask shape is {mask.shape}\")\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = self.add([primary_one_hot , attention_output])\n",
    "        print(f\"x +  add attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(x, -2) + tf.expand_dims(x, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        distances_bc = self.layer1(distances_bc)\n",
    "        print(f\"filter layer1 x shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        distances_bc = distances_bc * tf.expand_dims(mask, axis=-1)\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {x.shape}\")\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor6(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(7, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        self.resnet = res.resnet34()\n",
    "        self.vit = vit.vit_base_patch16_224_in21k()\n",
    "        self.add = keras.layers.Add()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(f\"mask shape is {mask.shape}\")\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = self.add([primary_one_hot , attention_output])\n",
    "        print(f\"x +  add attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(x, -2) + tf.expand_dims(x, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        distances_bc = self.layer1(distances_bc)\n",
    "        print(f\"filter layer1 x shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        distances_bc = distances_bc * tf.expand_dims(mask, axis=-1)\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        resnet = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {resnet.shape}\")\n",
    "        # x = self.layer1(x)\n",
    "        # print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        vit = self.vit(x)\n",
    "        print(f\"self.vit x shape is: {vit.shape}\")\n",
    "        x = tf.expand_dims(vit, axis=-1) + resnet\n",
    "        print(f\"end add x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor7(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(7, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(256, 16, 16,activation='gelu', padding=\"same\")\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        self.resnet = res.resnet34()\n",
    "        self.add = keras.layers.Add()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(f\"mask shape is {mask.shape}\")\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = self.add([primary_one_hot , attention_output])\n",
    "        print(f\"x +  add attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(x, -2) + tf.expand_dims(x, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        distances_bc = distances_bc * tf.expand_dims(mask, axis=-1)\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {x.shape}\")\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        x = tf.reshape(x, [tf.shape(x)[0], 256, 256])\n",
    "        print(f\"reshape x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinStructurePredictor6()\n",
    "model.optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.batch_size = 4\n",
    "epochs = 5\n",
    "def get_n_records(batch):\n",
    "    return batch['primary_onehot'].shape[0]\n",
    "def get_input_output_masks(batch):\n",
    "    inputs = {'primary_onehot':batch['primary_onehot']}\n",
    "    outputs = batch['true_distances']\n",
    "    masks = batch['distance_mask']\n",
    "    return inputs, outputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.reduce_sum(mask): 65536.0\n",
      "tf.reduce_sum(mask): 64009.0\n",
      "tf.reduce_sum(mask): 65536.0\n",
      "tf.reduce_sum(mask): 65536.0\n",
      "(4, 256, 21) (4, 256, 256) (4, 256, 256)\n",
      "mask shape is (4, 256, 256)\n",
      "start call --------------------\n",
      "primary_one_hot shape is (4, 256, 21)\n",
      "attention_output shape is (4, 256, 21)\n",
      "x +  add attention shape is (4, 256, 21)\n",
      "x dense shape is (4, 256, 64)\n",
      "expand_dims x shape is: (4, 256, 256, 64)\n",
      "filter layer0 x shape is: (4, 256, 256, 7)\n",
      "distances_bc shape is: (4, 256, 256, 1)\n",
      "filter layer1 x shape is: (4, 256, 256, 1)\n",
      "list of shape is (4, 256, 256, 7)  ,  [  4 256 256   7]  ,   (4, 256, 256, 1)\n",
      "concat result x is (4, 256, 256, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer ResNet_autoencoder: expected shape=(None, 256, 256, 8), found shape=(4, 256, 256, 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18352\\1637927251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'primary_onehot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\OEM\\.conda\\envs\\yzsnail_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18352\\1304179948.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdistances_bc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances_bc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"concat result x is {x.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"After resnet x shape is: {resnet.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# x = self.layer1(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\OEM\\.conda\\envs\\yzsnail_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\OEM\\.conda\\envs\\yzsnail_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    272\u001b[0m                              \u001b[1;34m' is incompatible with layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                              \u001b[1;34m': expected shape='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer ResNet_autoencoder: expected shape=(None, 256, 256, 8), found shape=(4, 256, 256, 15)"
     ]
    }
   ],
   "source": [
    "epoch_training_records = training_records.shuffle(buffer_size=256).batch(model.batch_size, drop_remainder=False)\n",
    "train_loss=utils.mse_loss\n",
    "for batch in epoch_training_records:\n",
    "    inputs, labels, masks = get_input_output_masks(batch)\n",
    "    print(f'tf.reduce_sum(mask): {tf.reduce_sum(masks[0])}')\n",
    "    print(f'tf.reduce_sum(mask): {tf.reduce_sum(masks[1])}')\n",
    "    print(f'tf.reduce_sum(mask): {tf.reduce_sum(masks[2])}')\n",
    "    print(f'tf.reduce_sum(mask): {tf.reduce_sum(masks[3])}')\n",
    "    with tf.GradientTape() as tape:\n",
    "        print(inputs['primary_onehot'].shape,labels.shape,masks.shape)\n",
    "        outputs = model(inputs, masks)\n",
    "        l = train_loss(outputs, labels, masks)\n",
    "        batch_loss = tf.reduce_sum(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 查看所有物理 GPU 设备\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzsnail_tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
