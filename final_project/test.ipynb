{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# suppress silly log messages from tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import structure_prediction_utils as utils\n",
    "from Autoencoder import AutoEncoder\n",
    "# import resnet_model as res\n",
    "import res_autoencoder as res\n",
    "importlib.reload(res)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([1806.5  322.7 6882.9], shape=(3,), dtype=float32)\n",
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "evolutionary shape= (5376,)\n",
      "id shape= (1,)\n",
      "primary shape= (256,)\n",
      "tertiary shape= (256, 3)\n",
      "primary_onehot shape= (256, 21)\n",
      "mask shape= (256,)\n",
      "true_distances shape= (256, 256)\n",
      "distance_mask shape= (256, 256)\n",
      "Value info of one data record, structure: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_folder = './'\n",
    "training_records = utils.load_preprocessed_data(data_folder, 'training.tfr')\n",
    "validate_records = utils.load_preprocessed_data(data_folder, 'validation.tfr')\n",
    "test_records = utils.load_preprocessed_data(data_folder, 'testing.tfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor0(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f\"inputs x shape is: {primary_one_hot.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor1(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(8, 8))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(8, 8))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=1, key_dim=2)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f\"inputs x shape is: {primary_one_hot.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        attention_output = self.attention(x, x, x)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = x + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor2(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = primary_one_hot + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# class Encoder(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#        super(Encoder, self).__init__()\n",
    "#        self.encoder_conv_1 = tf.keras.layers.Conv2D(\n",
    "#            filters=8,\n",
    "#            kernel_size=3,\n",
    "#            strides=2,\n",
    "#            padding='same',\n",
    "#            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#            activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#        )\n",
    "#        self.encoder_conv_2 = tf.keras.layers.Conv2D(\n",
    "#            filters=16,\n",
    "#            kernel_size=3,\n",
    "#            strides=2,\n",
    "#            padding='same',\n",
    "#            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#            activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#        )\n",
    "#        self.encoder_conv_3 = tf.keras.layers.Conv2D(\n",
    "#            filters=32,\n",
    "#            kernel_size=3,\n",
    "#            strides=2,\n",
    "#            padding='same',\n",
    "#            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#            activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#        )\n",
    "\n",
    "#     @tf.function\n",
    "#     def call(self, images):\n",
    "#       x = self.encoder_conv_1(images)\n",
    "#       x = self.encoder_conv_2(x)\n",
    "#       x = self.encoder_conv_3(x)\n",
    "#       return x\n",
    "    \n",
    "# class Decoder(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.decoder_deconv_1 = tf.keras.layers.Conv2DTranspose(\n",
    "#             filters=16,\n",
    "#             kernel_size=3,\n",
    "#             strides=2,\n",
    "#             padding='same',\n",
    "#             kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#             activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#         )\n",
    "#         self.decoder_deconv_2 = tf.keras.layers.Conv2DTranspose(\n",
    "#             filters=8,\n",
    "#             kernel_size=3,\n",
    "#             strides=2,\n",
    "#             padding='same',\n",
    "#             kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#             activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#         )\n",
    "#         self.decoder_deconv_3 = tf.keras.layers.Conv2DTranspose(\n",
    "#             filters=3,\n",
    "#             kernel_size=3,\n",
    "#             strides=2,\n",
    "#             padding='same',\n",
    "#             kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "#             activation=tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "#         )\n",
    "#     @tf.function\n",
    "#     def call(self, encoder_output):\n",
    "#       x = self.decoder_deconv_1(encoder_output)\n",
    "#       x = self.decoder_deconv_2(x)\n",
    "#       x = self.decoder_deconv_3(x)\n",
    "#       return x\n",
    "    \n",
    "# class AutoEncoder(tf.keras.Model):\n",
    "#     def __init__(self):\n",
    "#         super(AutoEncoder, self).__init__()\n",
    "#         self.encoder = Encoder()\n",
    "#         self.decoder = Decoder()\n",
    "\n",
    "#     @tf.function\n",
    "#     def call(self, inputs):\n",
    "#       encoded = self.encoder(inputs)\n",
    "#       decoded = self.decoder(encoded)\n",
    "#       return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor4(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.pooling = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.upsampling = keras.layers.UpSampling2D(size=(2, 2))\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        # self.encoder = Encoder()\n",
    "        # self.decoder = Decoder()\n",
    "        self.autencode = AutoEncoder()\n",
    "        self.resnet = res.resnet50()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = primary_one_hot + attention_output\n",
    "        print(f\"x + attention shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(primary_one_hot, -2) + tf.expand_dims(primary_one_hot, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "\n",
    "        x = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "\n",
    "\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.pooling(x)\n",
    "        print(f'after pooling x shape is {x.shape}')\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # x = self.encoder(x)\n",
    "        # print(f'after encoder shape is {x.shape}')\n",
    "        # x = self.decoder(x)\n",
    "        # print(f'after decoder shape is {x.shape}')\n",
    "        x = self.autencode(x)\n",
    "        print(f'autencode shape is {x.shape}')\n",
    "        # x = distances_bc\n",
    "        x = self.upsampling(x)\n",
    "        print(f\"after upsampling, x shape is: {x.shape}\")\n",
    "        # generate result\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinStructurePredictor5(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = keras.layers.Conv2D(5, 5, activation='gelu', padding=\"same\")\n",
    "        self.layer1 = keras.layers.Conv2D(1, 1, activation='gelu', padding=\"same\")\n",
    "        self.attention = keras.layers.MultiHeadAttention(num_heads=4, key_dim=16)\n",
    "        self.dense = keras.layers.Dense(64, activation='gelu')\n",
    "        self.resnet = res.resnet34()\n",
    "        self.add = keras.layers.Add()\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, mask=None):\n",
    "        print(f\"mask shape is {mask.shape}\")\n",
    "        print(\"start call\", '-'*20)\n",
    "        primary_one_hot = inputs['primary_onehot']\n",
    "        print(f'primary_one_hot shape is {primary_one_hot.shape}')\n",
    "        attention_output = self.attention(primary_one_hot, primary_one_hot, primary_one_hot)\n",
    "        print(f'attention_output shape is {attention_output.shape}')\n",
    "        x = self.add([primary_one_hot , attention_output])\n",
    "        print(f\"x +  add attention shape is {x.shape}\")\n",
    "        x = self.dense(x)\n",
    "        print(f\"x dense shape is {x.shape}\")\n",
    "        # outer sum to get a NUM_RESIDUES x NUM_RESIDUES x embedding size\n",
    "        x = tf.expand_dims(x, -2) + tf.expand_dims(x, -3)\n",
    "        print(f\"expand_dims x shape is: {x.shape}\")\n",
    "        # filter the initial representation into an embedded representation\n",
    "        x = self.layer0(x)\n",
    "        print(f\"filter layer0 x shape is: {x.shape}\")\n",
    "        # add positional distance information\n",
    "        r = tf.range(0, utils.NUM_RESIDUES, dtype=tf.float32)\n",
    "        distances = tf.abs(tf.expand_dims(r, -1) - tf.expand_dims(r, -2))\n",
    "        distances_bc = tf.expand_dims(\n",
    "            tf.broadcast_to(distances, [primary_one_hot.shape[0], utils.NUM_RESIDUES, utils.NUM_RESIDUES]), -1)\n",
    "        print(f\"distances_bc shape is: {distances_bc.shape}\")\n",
    "        print(f\"list of shape is {x.shape}  ,  {tf.shape(x * distances_bc)}  ,   {distances_bc.shape}\")\n",
    "        distances_bc = distances_bc * tf.expand_dims(mask, axis=-1)\n",
    "        x = tf.concat([x, x * distances_bc, distances_bc], axis=-1)\n",
    "        print(f\"concat result x is {x.shape}\")\n",
    "        x = self.resnet(x)\n",
    "        print(f\"After resnet x shape is: {x.shape}\")\n",
    "        x = self.layer1(x)\n",
    "        print(f\"filter layer1 x shape is: {x.shape}\")\n",
    "        print(\"End call\", '-'*20)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinStructurePredictor5()\n",
    "model.optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "model.batch_size = 1\n",
    "epochs = 5\n",
    "def get_n_records(batch):\n",
    "    return batch['primary_onehot'].shape[0]\n",
    "def get_input_output_masks(batch):\n",
    "    inputs = {'primary_onehot':batch['primary_onehot']}\n",
    "    outputs = batch['true_distances']\n",
    "    masks = batch['distance_mask']\n",
    "    return inputs, outputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 21) (1, 256, 256) (1, 256, 256)\n",
      "mask shape is (1, 256, 256)\n",
      "start call --------------------\n",
      "primary_one_hot shape is (1, 256, 21)\n",
      "attention_output shape is (1, 256, 21)\n",
      "x +  add attention shape is (1, 256, 21)\n",
      "x dense shape is (1, 256, 64)\n",
      "expand_dims x shape is: (1, 256, 256, 64)\n",
      "filter layer0 x shape is: (1, 256, 256, 5)\n",
      "distances_bc shape is: (1, 256, 256, 1)\n",
      "list of shape is (1, 256, 256, 5)  ,  [  1 256 256   5]  ,   (1, 256, 256, 1)\n",
      "concat result x is (1, 256, 256, 11)\n",
      "After resnet x shape is: (1, 256, 256, 8)\n",
      "filter layer1 x shape is: (1, 256, 256, 1)\n",
      "End call --------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_training_records = training_records.shuffle(buffer_size=256).batch(model.batch_size, drop_remainder=False)\n",
    "train_loss=utils.mse_loss\n",
    "for batch in epoch_training_records:\n",
    "    inputs, labels, masks = get_input_output_masks(batch)\n",
    "    with tf.GradientTape() as tape:\n",
    "        print(inputs['primary_onehot'].shape,labels.shape,masks.shape)\n",
    "        outputs = model(inputs, masks)\n",
    "        l = train_loss(outputs, labels, masks)\n",
    "        batch_loss = tf.reduce_sum(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 查看所有物理 GPU 设备\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzsnail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
